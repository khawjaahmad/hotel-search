name: Hotel Booking QA Pipeline - Enhanced

on:
  push:
    branches: [main, master, develop]
    paths:
      - "lib/**"
      - "test/**"
      - "integration_test/**"
      - "android/**"
      - "pubspec.yaml"
  pull_request:
    branches: [main, master, develop]
  workflow_dispatch:
    inputs:
      test_target:
        description: 'Test target (file or directory)'
        required: false
        default: 'integration_test/'
        type: string
      device_matrix:
        description: 'Device matrix size'
        required: false
        default: 'standard'
        type: choice
        options:
          - minimal
          - standard
          - comprehensive
      run_firebase:
        description: 'Run Firebase Test Lab'
        required: false
        default: true
        type: boolean

env:
  FLUTTER_VERSION: "3.24.0"
  FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
  JAVA_VERSION: "17"

jobs:
  # Quick validation for fast feedback
  quick_validation:
    name: Quick Validation & Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15
    outputs:
      should_run_integration: ${{ steps.changes.outputs.integration_needed }}
      test_complexity: ${{ steps.analysis.outputs.complexity }}
      affected_features: ${{ steps.analysis.outputs.features }}
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better change analysis

      - name: Analyze Changes
        id: changes
        run: |
          # Analyze changed files to determine test strategy
          CHANGED_FILES=$(git diff --name-only HEAD~1 || git ls-files)
          echo "Changed files:"
          echo "$CHANGED_FILES"
          
          # Determine if integration tests are needed
          if echo "$CHANGED_FILES" | grep -E "(integration_test/|lib/features/)" > /dev/null; then
            echo "integration_needed=true" >> $GITHUB_OUTPUT
            echo "üîÑ Integration tests required due to feature changes"
          elif echo "$CHANGED_FILES" | grep -E "(lib/)" > /dev/null; then
            echo "integration_needed=true" >> $GITHUB_OUTPUT
            echo "üîÑ Integration tests required due to lib changes"
          else
            echo "integration_needed=false" >> $GITHUB_OUTPUT
            echo "‚è≠Ô∏è Integration tests skipped - no relevant changes"
          fi

      - name: Feature Impact Analysis
        id: analysis
        run: |
          # Analyze which features are affected
          FEATURES=""
          if git diff --name-only HEAD~1 | grep -q "features/hotels/"; then
            FEATURES="$FEATURES hotels"
          fi
          if git diff --name-only HEAD~1 | grep -q "features/favorites/"; then
            FEATURES="$FEATURES favorites"
          fi
          if git diff --name-only HEAD~1 | grep -q "features/account/"; then
            FEATURES="$FEATURES account"
          fi
          
          # Determine test complexity
          COMPLEXITY="standard"
          if [[ -n "$FEATURES" ]]; then
            WORD_COUNT=$(echo "$FEATURES" | wc -w)
            if [[ $WORD_COUNT -gt 2 ]]; then
              COMPLEXITY="comprehensive"
            elif [[ $WORD_COUNT -eq 1 ]]; then
              COMPLEXITY="minimal"
            fi
          fi
          
          echo "features=$FEATURES" >> $GITHUB_OUTPUT
          echo "complexity=$COMPLEXITY" >> $GITHUB_OUTPUT
          echo "üéØ Affected features: $FEATURES"
          echo "üìä Test complexity: $COMPLEXITY"

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: "stable"
          cache: true

      - name: Install Dependencies
        env:
          SERPAPI_API_KEY: ${{ secrets.SERPAPI_API_KEY }}
        run: |
          flutter pub get
          dart run build_runner build --delete-conflicting-outputs

      - name: Static Analysis
        run: |
          echo "üîç Running static analysis..."
          dart analyze --fatal-infos
          dart format --output=none --set-exit-if-changed .

      - name: Unit & Widget Tests
        run: |
          echo "üß™ Running unit and widget tests..."
          flutter test test/unit/ test/widgets/ \
            --reporter=expanded \
            --coverage \
            --test-randomize-ordering-seed=random

      - name: Coverage Analysis
        run: |
          if command -v lcov &> /dev/null; then
            lcov --summary coverage/lcov.info
            
            # Extract coverage percentage
            COVERAGE=$(lcov --summary coverage/lcov.info 2>/dev/null | grep "lines" | grep -o '[0-9.]*%' | head -1 || echo "0%")
            echo "üìä Test Coverage: $COVERAGE"
            
            # Check minimum coverage threshold
            COVERAGE_NUM=$(echo $COVERAGE | sed 's/%//')
            if (( $(echo "$COVERAGE_NUM < 85" | bc -l) )); then
              echo "‚ùå Coverage below threshold: $COVERAGE < 85%"
              exit 1
            fi
          fi

      - name: Upload Coverage Reports
        uses: codecov/codecov-action@v3
        with:
          file: coverage/lcov.info
          fail_ci_if_error: false
          flags: unittests

  # Firebase Test Lab execution with enhanced configuration
  firebase_test_lab:
    name: Firebase Test Lab Android
    runs-on: ubuntu-latest
    needs: quick_validation
    if: needs.quick_validation.outputs.should_run_integration == 'true' && (github.event.inputs.run_firebase != 'false')
    timeout-minutes: 30
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Java 17
        uses: actions/setup-java@v4
        with:
          distribution: "temurin"
          java-version: "17"

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: "stable"
          cache: true

      - name: Setup Patrol CLI
        run: |
          dart pub global activate patrol_cli
          echo "$HOME/.pub-cache/bin" >> $GITHUB_PATH

      - name: Install Dependencies
        env:
          SERPAPI_API_KEY: ${{ secrets.SERPAPI_API_KEY }}
        run: |
          flutter pub get
          dart run build_runner build --delete-conflicting-outputs

      - name: Authenticate Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GOOGLE_CLOUD_SERVICE_ACCOUNT_KEY }}

      - name: Setup Google Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ secrets.FIREBASE_PROJECT_ID }}

      - name: Build Patrol APKs
        run: |
          echo "Building APKs for Firebase Test Lab..."
          patrol build android --target integration_test/tests/dashboard_test.dart --release --verbose
          
          # Verify APKs exist
          ls -la build/app/outputs/apk/debug/
          ls -la build/app/outputs/apk/androidTest/debug/

      - name: Run Firebase Test Lab
        env:
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
        run: |
          TIMESTAMP=$(date +%Y%m%d-%H%M%S)
          RESULTS_DIR="patrol-github-${TIMESTAMP}"
          
          gcloud firebase test android run \
            --type instrumentation \
            --app build/app/outputs/apk/debug/app-debug.apk \
            --test build/app/outputs/apk/androidTest/debug/app-debug-androidTest.apk \
            --device model=shiba,version=34,locale=en,orientation=portrait \
            --device model=oriole,version=33,locale=en,orientation=portrait \
            --timeout 20m \
            --results-bucket=${FIREBASE_PROJECT_ID}-test-results \
            --results-dir="${RESULTS_DIR}" \
            --environment-variables \
              clearPackageData=true,\
              disableAnalytics=true,\
              PATROL_WAIT=10000 \
            --use-orchestrator \
            --performance-metrics \
            --project $FIREBASE_PROJECT_ID \
            --format=json > firebase_results.json
          
          # Store results directory for artifact download
          echo "RESULTS_DIR=${RESULTS_DIR}" >> $GITHUB_ENV

      - name: Check Results
        run: |
          if [ -f firebase_results.json ]; then
            OUTCOME=$(jq -r '.outcome // "UNKNOWN"' firebase_results.json)
            TEST_MATRIX_ID=$(jq -r '.testMatrixId // "unknown"' firebase_results.json)
            
            echo "Firebase Test Outcome: $OUTCOME"
            echo "Test Matrix ID: $TEST_MATRIX_ID"
            
            # Create summary report
            cat > test_summary.md << EOF
          # Firebase Test Lab Results
          
          ## Test Details
          - **Outcome**: $OUTCOME
          - **Test Matrix ID**: $TEST_MATRIX_ID
          - **Timestamp**: $(date)
          - **Test Target**: integration_test/tests/dashboard_test.dart
          - **Devices Tested**: 2 (Pixel 8, Pixel 6)
          
          ## Device Matrix
          - **Device 1**: Pixel 8 (shiba) - Android 34
          - **Device 2**: Pixel 6 (oriole) - Android 33
          
          ## Results Location
          - **Firebase Console**: https://console.firebase.google.com/project/${FIREBASE_PROJECT_ID}/testlab/histories/
          - **Cloud Storage**: https://console.cloud.google.com/storage/browser/${FIREBASE_PROJECT_ID}-test-results/${RESULTS_DIR}
          EOF
          
            if [ "$OUTCOME" = "PASSED" ]; then
              echo "‚úÖ Firebase tests passed" >> test_summary.md
              echo "‚úÖ Firebase tests passed"
            else
              echo "‚ùå Firebase tests failed" >> test_summary.md
              echo "‚ùå Firebase tests failed"
              exit 1
            fi
          else
            echo "‚ùå No results file found"
            exit 1
          fi

      - name: Download Test Artifacts
        if: always()
        env:
          FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
        run: |
          echo "üì• Downloading test artifacts..."
          mkdir -p firebase_artifacts
          
          # Download screenshots and logs only (no videos)
          gsutil -m cp -r "gs://${FIREBASE_PROJECT_ID}-test-results/${RESULTS_DIR}/*" firebase_artifacts/ || echo "Some artifacts may not be available yet"
          
          # Remove video files if any were downloaded
          find firebase_artifacts -name "*.mp4" -delete 2>/dev/null || true
          
          # List downloaded files
          echo "Downloaded artifacts:"
          find firebase_artifacts -type f -name "*.png" -o -name "*.xml" -o -name "*.json" | head -20

      - name: Generate Test Report
        if: always()
        run: |
          echo "üìä Generating comprehensive test report..."
          
          # Create HTML report
          cat > firebase_report.html << 'EOF'
          <!DOCTYPE html>
          <html>
          <head>
              <title>Firebase Test Lab Results</title>
              <style>
                  body { font-family: Arial, sans-serif; margin: 20px; }
                  .header { background: #4285f4; color: white; padding: 20px; border-radius: 8px; }
                  .device { border: 1px solid #ddd; margin: 10px 0; padding: 15px; border-radius: 8px; }
                  .passed { border-left: 5px solid #34a853; }
                  .failed { border-left: 5px solid #ea4335; }
                  .artifact { margin: 5px 0; }
                  .screenshot { max-width: 300px; margin: 10px; border: 1px solid #ddd; }
              </style>
          </head>
          <body>
              <div class="header">
                  <h1>üß™ Firebase Test Lab Results</h1>
                  <p>Hotel Booking App - Patrol Integration Tests</p>
              </div>
          EOF
          
          # Add test summary
          if [ -f test_summary.md ]; then
            echo "<div class='summary'>" >> firebase_report.html
            echo "<h2>Test Summary</h2>" >> firebase_report.html
            
            OUTCOME=$(jq -r '.outcome // "UNKNOWN"' firebase_results.json)
            if [ "$OUTCOME" = "PASSED" ]; then
              echo "<div class='device passed'>" >> firebase_report.html
              echo "<h3>‚úÖ All Tests Passed</h3>" >> firebase_report.html
            else
              echo "<div class='device failed'>" >> firebase_report.html
              echo "<h3>‚ùå Some Tests Failed</h3>" >> firebase_report.html
            fi
            echo "</div></div>" >> firebase_report.html
          fi
          
          # Add device results if available
          echo "<h2>üì± Device Results</h2>" >> firebase_report.html
          
          # Check for device-specific results
          if [ -d "firebase_artifacts" ]; then
            echo "<div class='device'>" >> firebase_report.html
            echo "<h3>Device Test Artifacts</h3>" >> firebase_report.html
            
            # List screenshots
            if find firebase_artifacts -name "*.png" | head -1 > /dev/null 2>&1; then
              echo "<h4>üì∏ Screenshots</h4>" >> firebase_report.html
              find firebase_artifacts -name "*.png" | head -10 | while read screenshot; do
                if [ -f "$screenshot" ]; then
                  filename=$(basename "$screenshot")
                  echo "<div class='artifact'>üì∏ $filename</div>" >> firebase_report.html
                fi
              done
            fi
            
            # List test logs
            if find firebase_artifacts -name "*.xml" -o -name "*.json" | head -1 > /dev/null 2>&1; then
              echo "<h4>üìã Test Reports</h4>" >> firebase_report.html
              find firebase_artifacts -name "*.xml" -o -name "*.json" | head -10 | while read log; do
                if [ -f "$log" ]; then
                  filename=$(basename "$log")
                  echo "<div class='artifact'>üìã $filename</div>" >> firebase_report.html
                fi
              done
            fi
            
            echo "</div>" >> firebase_report.html
          fi
          
          # Close HTML
          echo "<div class='footer'>" >> firebase_report.html
          echo "<p>Generated on: $(date)</p>" >> firebase_report.html
          echo "<p>GitHub Run ID: ${{ github.run_id }}</p>" >> firebase_report.html
          echo "</div></body></html>" >> firebase_report.html
          
          echo "‚úÖ Test report generated: firebase_report.html"

      - name: Upload Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: firebase-test-results
          path: |
            firebase_results.json
            test_summary.md
            firebase_report.html
            firebase_artifacts/**
          retention-days: 30

      - name: Comment PR with Results
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            // Read test summary
            let summary = '# üß™ Firebase Test Lab Results\n\n';
            
            try {
              if (fs.existsSync('test_summary.md')) {
                summary += fs.readFileSync('test_summary.md', 'utf8');
              }
              
              // Add quick stats
              summary += '\n## üìä Quick Stats\n';
              summary += '- **Devices**: 2 (Pixel 8, Pixel 6)\n';
              summary += '- **Test Type**: Patrol Integration Tests\n';
              summary += '- **Target**: `integration_test/tests/dashboard_test.dart`\n';
              
              // Add links
              summary += '\n## üîó Links\n';
              summary += `- [GitHub Action Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n`;
              summary += `- [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}#artifacts)\n`;
              
              // Post comment
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: summary
              });
            } catch (error) {
              console.log('Error posting comment:', error.message);
            }

  # Final status consolidation
  final_status:
    name: Final Status & Reporting
    runs-on: ubuntu-latest
    needs: [quick_validation, firebase_test_lab]
    if: always()
    steps:
      - name: Collect Results
        id: results
        run: |
          echo "üìä Collecting pipeline results..."
          
          # Unit/Widget tests
          if [ "${{ needs.quick_validation.result }}" = "success" ]; then
            echo "‚úÖ Unit & Widget Tests: PASSED"
            UNIT_STATUS="PASSED"
          else
            echo "Unit & Widget Tests: FAILED"
            UNIT_STATUS="FAILED"
          fi
          
          # Firebase Test Lab
          if [ "${{ needs.firebase_test_lab.result }}" = "success" ]; then
            echo "‚úÖ Firebase Test Lab: PASSED"
            FIREBASE_STATUS="PASSED"
          elif [ "${{ needs.firebase_test_lab.result }}" = "skipped" ]; then
            echo "‚è≠Ô∏è Firebase Test Lab: SKIPPED"
            FIREBASE_STATUS="SKIPPED"
          else
            echo "‚ùå Firebase Test Lab: FAILED"
            FIREBASE_STATUS="FAILED"
          fi
          
          # Overall status
          if [[ "$UNIT_STATUS" = "PASSED" && 
                ("$FIREBASE_STATUS" = "PASSED" || "$FIREBASE_STATUS" = "SKIPPED") ]]; then
            OVERALL_STATUS="SUCCESS"
            echo "üéâ Overall Pipeline Status: SUCCESS"
          else
            OVERALL_STATUS="FAILURE"
            echo "üí• Overall Pipeline Status: FAILURE"
          fi
          
          # Export for summary
          echo "unit_status=$UNIT_STATUS" >> $GITHUB_OUTPUT
          echo "firebase_status=$FIREBASE_STATUS" >> $GITHUB_OUTPUT  
          echo "overall_status=$OVERALL_STATUS" >> $GITHUB_OUTPUT

      - name: Generate Pipeline Summary
        run: |
          echo "# üèÅ Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Unit & Widget Tests**: ${{ steps.results.outputs.unit_status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Firebase Test Lab**: ${{ steps.results.outputs.firebase_status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Overall Status: ${{ steps.results.outputs.overall_status }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### üîó Links" >> $GITHUB_STEP_SUMMARY
          echo "- [Action Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY
          echo "- [Firebase Console](https://console.firebase.google.com/project/${{ env.FIREBASE_PROJECT_ID }}/testlab/histories/)" >> $GITHUB_STEP_SUMMARY

      - name: Final Result
        run: |
          if [ "${{ steps.results.outputs.overall_status }}" = "SUCCESS" ]; then
            echo "üéâ All tests passed!"
            exit 0
          else
            echo "üí• Pipeline failed"
            exit 1
          fi